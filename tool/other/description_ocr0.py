import os
import re
import fitz  # PyMuPDF
from paddleocr import PaddleOCR
from PIL import Image
import cv2
import numpy as np

ocr = PaddleOCR(use_angle_cls=True, lang="ch", show_log=False)  # ç§»é™¤ structure å‚æ•°

def restructure_paragraphs(text):
    """æŒ‰ä¸“åˆ©æ ¼å¼é‡ç»„æ®µè½"""
    pattern = re.compile(r"\[(\d{4})\]")
    matches = list(pattern.finditer(text))

    if not matches:
        return [text.strip()]

    paragraphs = []

    for i in range(len(matches)):
        start = matches[i].end()
        end = matches[i+1].start() if i + 1 < len(matches) else len(text)
        para_text = text[start:end].strip()

        if not para_text:
            continue

        lines = [line.strip() for line in para_text.splitlines() if line.strip()]
        if len(lines) == 1:
            paragraphs.append(lines[0])
        elif len(lines) >= 2:
            if lines[-1].endswith("ã€‚"):
                paragraphs.append("".join(lines))
            else:
                paragraphs.append("".join(lines[:-1]))
                paragraphs.append(lines[-1])

    return paragraphs

def detect_tables(image_path):
    """
    ä½¿ç”¨OpenCVæ£€æµ‹è¡¨æ ¼åŒºåŸŸï¼ˆæ›¿ä»£PaddleOCRçš„structureåŠŸèƒ½ï¼‰
    è¿”å›è¡¨æ ¼åŒºåŸŸçš„åæ ‡åˆ—è¡¨
    """
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # äºŒå€¼åŒ–
    thresh = cv2.adaptiveThreshold(
        ~gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, -10
    )
    
    # æ£€æµ‹æ¨ªçº¿å’Œç«–çº¿
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))
    
    horizontal_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)
    vertical_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)
    
    # åˆå¹¶æ¨ªçº¿å’Œç«–çº¿
    table_mask = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0.0)
    table_mask = cv2.dilate(table_mask, cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)), iterations=1)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # è¿‡æ»¤å°åŒºåŸŸï¼Œä¿ç•™è¡¨æ ¼
    table_areas = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        if w > 100 and h > 50:  # è¿‡æ»¤å°åŒºåŸŸ
            table_areas.append((x, y, x + w, y + h))
    
    return table_areas

def extract_text_and_tables(pdf_path, output_text_path, table_output_dir):
    """æå–PDFä¸­çš„æ–‡æœ¬å’Œè¡¨æ ¼"""
    os.makedirs(table_output_dir, exist_ok=True)

    doc = fitz.open(pdf_path)
    results = []

    for page_num in range(len(doc)):
        print(f"æ­£åœ¨å¤„ç†ç¬¬{page_num + 1}/{len(doc)}é¡µ")
        page = doc.load_page(page_num)
        text = page.get_text("text").strip()

        # ç”Ÿæˆé«˜åˆ†è¾¨ç‡é¡µé¢å›¾åƒ
        pix = page.get_pixmap(dpi=300)
        img_path = f"temp_page_{page_num + 1}.png"
        pix.save(img_path)

        # 1. æå–æ–‡æœ¬å†…å®¹
        ocr_result = ocr.ocr(img_path, cls=True)
        lines = []
        for line in ocr_result[0]:
            if isinstance(line, list) and len(line) >= 2:
                lines.append(line[1][0])
        page_text = "\n".join(lines)
        results.append(page_text)

        # 2. ä½¿ç”¨OpenCVæ£€æµ‹å¹¶æå–è¡¨æ ¼åŒºåŸŸ
        table_areas = detect_tables(img_path)
        for i, (x1, y1, x2, y2) in enumerate(table_areas):
            img = Image.open(img_path)
            table_img = img.crop((x1, y1, x2, y2))
            table_path = os.path.join(table_output_dir, f"page_{page_num + 1}_table_{i + 1}.jpg")
            table_img.save(table_path)

        print(f"ç¬¬{page_num + 1}é¡µï¼šæå–åˆ°è¡¨æ ¼ {len(table_areas)} ä¸ª")

    # åˆå¹¶æ‰€æœ‰é¡µé¢æ–‡æœ¬å¹¶ç»“æ„åŒ–å¤„ç†
    full_text = "\n".join(results)
    paragraphs = restructure_paragraphs(full_text)

    # ä¿å­˜ç»“æœ
    with open(output_text_path, "w", encoding="utf-8") as f:
        for para in paragraphs:
            f.write(para.strip() + "\n\n")

    print(f"\n[ğŸ‰] æ–‡æœ¬ä¸è¡¨æ ¼æå–å®Œæˆï¼æ–‡æœ¬è¾“å‡ºï¼š{output_text_path}ï¼Œè¡¨æ ¼å›¾ç‰‡ä¿å­˜ç›®å½•ï¼š{table_output_dir}")

# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    pdf_file = r"/workspace/split_pdfs/CN111964678B/description/description.pdf"
    output_text = r"/workspace/tool/chapter_processing/description.txt"
    table_img_output_dir = r"/workspace/tool/chapter_processing/table_output"
    extract_text_and_tables(pdf_file, output_text, table_img_output_dir)
import os
import re
import cv2
import pdfplumber
import numpy as np
from PIL import Image
from paddleocr import PaddleOCR

ocr = PaddleOCR(use_angle_cls=False, lang='ch')  # ä¸­æ–‡ OCR

def extract_figures_by_label(pdf_path, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    last_page_number = None  # ç”¨äºè®°å½•æœ€åä¸€ä¸ªæœ‰æ•ˆé¡µç 
    
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        
        for i, page in enumerate(pdf.pages):
            pil_img = page.to_image(resolution=300).original.convert("RGB")
            img_cv = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            height, width = img_cv.shape[:2]

            # OCR è¯†åˆ«
            results = ocr.ocr(np.array(pil_img), cls=False)
            if not results or not results[0]:
                print(f"âš ï¸ Page {i+1}: æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡å­—")
                continue

            # æ”¹è¿›çš„é¡µç æå–æ–¹æ³•
            page_number = extract_page_number_improved(results[0], height, width, i+1, total_pages, last_page_number)
            
            if page_number is None:
                print(f"âš ï¸ Page {i+1}: æœªæ£€æµ‹åˆ°é¡µç ï¼Œä¸”æ— æ³•æ¨æ–­")
                continue
            else:
                # æ›´æ–°æœ€åä¸€ä¸ªæœ‰æ•ˆé¡µç 
                last_page_number = int(page_number)

            print(f"ğŸ“„ Page {i+1}: é¡µç ä¸º {page_number}")

            # è¯†åˆ«å›¾å·æ ‡ç­¾ï¼Œå¹¶è·å–å…¶é¡¶éƒ¨å’Œåº•éƒ¨ä½ç½®
            label_boxes = []
            for line in results[0]:
                text = line[1][0] if isinstance(line[1], (list, tuple)) else str(line[1])
                if re.match(r'^å›¾\s?\d+', text.strip()):
                    try:
                        points = line[0]
                        y_coords = [p[1] for p in points]
                        y_top = min(y_coords)
                        y_bottom = max(y_coords)
                        label_boxes.append((y_top, y_bottom, text.strip().replace(" ", "")))
                    except Exception as e:
                        print(f"âš ï¸ åæ ‡è§£æé”™è¯¯: {e}")
                        continue

            if not label_boxes:
                print(f"âš ï¸ Page {i+1}: æœªæ£€æµ‹åˆ°å›¾æ ‡ç­¾")
                continue

            # æŒ‰ç…§ y_top ä»ä¸‹å¾€ä¸Šæ’åºï¼ˆä»é¡µé¢åº•éƒ¨å¾€ä¸Šï¼‰
            label_boxes = sorted(label_boxes, key=lambda x: x[0], reverse=True)

            for idx in range(len(label_boxes)):
                y_top_curr = int(label_boxes[idx][0])
                label = label_boxes[idx][2]

                if idx + 1 < len(label_boxes):
                    y_bottom_prev = int(label_boxes[idx + 1][1])  # ä¸Šä¸€ä¸ª label çš„åº•éƒ¨
                else:
                    y_bottom_prev = int(height * 0.07)  # è·³è¿‡é¡µçœ‰ 

                y_top = max(0, y_bottom_prev)
                y_bottom = min(height, y_top_curr)

                if y_bottom <= y_top:
                    print(f"âš ï¸ {label}: æ— æ•ˆçš„è£å‰ªåŒºåŸŸ (y_top={y_top}, y_bottom={y_bottom})")
                    continue

                cropped = img_cv[y_top:y_bottom, :]
                out_path = os.path.abspath(os.path.join(output_dir, f"{label}_page{page_number}.png"))
                cv2.imwrite(out_path, cropped)
                print(f"âœ… æå– {label} (é¡µç : {page_number}) ä¿å­˜è‡³ {out_path}")


def extract_page_number_improved(ocr_results, height, width, current_page_index, total_pages, last_page_number):
    """
    æ”¹è¿›çš„é¡µç æå–æ–¹æ³•
    """
    page_candidates = []
    
    # 1. æ”¶é›†æ‰€æœ‰å¯èƒ½çš„é¡µç å€™é€‰
    for line in ocr_results:
        text = line[1][0] if isinstance(line[1], (list, tuple)) else str(line[1])
        text = text.strip()
        
        # è·å–æ–‡æœ¬ä½ç½®ä¿¡æ¯
        points = line[0]
        x_coords = [p[0] for p in points]
        y_coords = [p[1] for p in points]
        x_center = (min(x_coords) + max(x_coords)) / 2
        y_center = (min(y_coords) + max(y_coords)) / 2
        y_bottom = max(y_coords)
        
        # å¤šç§é¡µç æ¨¡å¼åŒ¹é…
        page_num = None
        confidence = 0
        
        # æ¨¡å¼1: çº¯æ•°å­—
        if re.match(r'^\d+$', text):
            page_num = int(text)
            confidence = 3
        
        # æ¨¡å¼2: è´Ÿå·+æ•°å­— (æœ‰æ—¶OCRä¼šæŠŠé¡µç è¯†åˆ«æˆè´Ÿå·)
        elif re.match(r'^-\d+$', text):
            page_num = int(text[1:])
            confidence = 2
        
        # æ¨¡å¼3: ç¬¬Xé¡µæ ¼å¼
        elif re.match(r'^ç¬¬?\s*(\d+)\s*é¡µ?$', text):
            match = re.search(r'(\d+)', text)
            if match:
                page_num = int(match.group(1))
                confidence = 4
        
        # æ¨¡å¼4: åŒ…å«æ•°å­—çš„çŸ­æ–‡æœ¬ (å¦‚ "- 5 -", "5.", "Page 5")
        elif len(text) <= 10:
            numbers = re.findall(r'\d+', text)
            if len(numbers) == 1:
                page_num = int(numbers[0])
                confidence = 1
        
        if page_num is not None:
            # ä½ç½®è¯„åˆ† (åº•éƒ¨ä¸­å¤®å¾—åˆ†æœ€é«˜)
            position_score = 0
            
            # å‚ç›´ä½ç½®è¯„åˆ† (åº•éƒ¨å¾—åˆ†é«˜)
            if y_bottom > height * 0.85:
                position_score += 3
            elif y_bottom > height * 0.75:
                position_score += 2
            elif y_bottom > height * 0.6:
                position_score += 1
            
            # æ°´å¹³ä½ç½®è¯„åˆ† (ä¸­å¤®å¾—åˆ†é«˜)
            if width * 0.4 < x_center < width * 0.6:
                position_score += 2
            elif width * 0.3 < x_center < width * 0.7:
                position_score += 1
            
            # é¡µç åˆç†æ€§æ£€æŸ¥
            reasonableness_score = 0
            if 1 <= page_num <= total_pages * 2:  # å…è®¸ä¸€å®šçš„é¡µç èŒƒå›´
                reasonableness_score = 2
            elif 1 <= page_num <= 1000:  # åŸºæœ¬åˆç†èŒƒå›´
                reasonableness_score = 1
            
            total_score = confidence + position_score + reasonableness_score
            page_candidates.append((page_num, total_score, text))
    
    # 2. é€‰æ‹©æœ€ä½³å€™é€‰
    if page_candidates:
        # æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©å¾—åˆ†æœ€é«˜çš„
        page_candidates.sort(key=lambda x: x[1], reverse=True)
        best_candidate = page_candidates[0]
        
        # å¦‚æœæœ€é«˜åˆ†å¤§äºç­‰äº4ï¼Œç›´æ¥ä½¿ç”¨
        if best_candidate[1] >= 4:
            return str(best_candidate[0])
        
        # å¦‚æœæœ‰ä¸Šä¸€é¡µçš„é¡µç ï¼Œæ£€æŸ¥è¿ç»­æ€§
        if last_page_number is not None:
            for candidate in page_candidates:
                if abs(candidate[0] - (last_page_number + 1)) <= 1:  # å…è®¸Â±1çš„è¯¯å·®
                    return str(candidate[0])
        
        # å¦åˆ™ä½¿ç”¨å¾—åˆ†æœ€é«˜çš„å€™é€‰
        if best_candidate[1] >= 2:
            return str(best_candidate[0])
    
    # 3. æ¨æ–­æ–¹æ³•æ”¹è¿›
    if last_page_number is not None:
        # åŸºäºä¸Šä¸€é¡µæ¨æ–­
        inferred_page = last_page_number + 1
        
        # æ£€æŸ¥æ¨æ–­çš„é¡µç æ˜¯å¦åˆç†
        if inferred_page <= total_pages * 2:  # åˆç†èŒƒå›´å†…
            print(f"   æ¨æ–­é¡µç : {inferred_page} (åŸºäºä¸Šä¸€é¡µ: {last_page_number})")
            return str(inferred_page)
    
    # 4. æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºPDFé¡µé¢ç´¢å¼•æ¨æ–­
    if current_page_index <= total_pages:
        print(f"   ä½¿ç”¨PDFé¡µé¢ç´¢å¼•ä½œä¸ºé¡µç : {current_page_index}")
        return str(current_page_index)
    
    return None
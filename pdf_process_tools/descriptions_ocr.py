import os
import re
import cv2
import numpy as np
import pdfplumber
from PIL import Image, ImageEnhance
from paddleocr import PPStructure, PaddleOCR
import fitz  # PyMuPDF

def detect_pdf_type(pdf_path, sample_pages=3):
    """
    æ£€æµ‹PDFç±»å‹ï¼šæ–‡æœ¬å‹ vs å›¾ç‰‡å‹
    
    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        sample_pages: é‡‡æ ·é¡µæ•°è¿›è¡Œæ£€æµ‹
    
    Returns:
        'text': æ–‡æœ¬å‹PDF
        'image': å›¾ç‰‡å‹PDF
        'mixed': æ··åˆå‹PDF
    """
    print("ğŸ” æ­£åœ¨åˆ†æPDFç±»å‹...")
    
    text_pages = 0
    image_pages = 0
    total_checked = 0
    
    with pdfplumber.open(pdf_path) as pdf:
        # æ£€æŸ¥å‰å‡ é¡µæ¥åˆ¤æ–­ç±»å‹
        pages_to_check = min(sample_pages, len(pdf.pages))
        
        for i in range(pages_to_check):
            page = pdf.pages[i]
            text = page.extract_text()
            
            total_checked += 1
            
            # åˆ¤æ–­æ ‡å‡†ï¼š
            # 1. æ–‡æœ¬é•¿åº¦
            # 2. ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
            # 3. æœ‰æ•ˆæ–‡æœ¬è¡Œæ•°
            if text and len(text.strip()) > 50:
                # è®¡ç®—ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
                chinese_chars = len(re.findall(r'[\u4e00-\u9fa5]', text))
                total_chars = len(re.sub(r'\s', '', text))
                
                if total_chars > 0:
                    chinese_ratio = chinese_chars / total_chars
                    # å¦‚æœä¸­æ–‡å­—ç¬¦å æ¯”>10%ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆæ–‡æœ¬é¡µ
                    if chinese_ratio > 0.1 or total_chars > 200:
                        text_pages += 1
                        continue
            
            # å¦‚æœæ–‡æœ¬æå–å¤±è´¥æˆ–æ–‡æœ¬å¾ˆå°‘ï¼Œåˆ¤æ–­ä¸ºå›¾ç‰‡é¡µ
            image_pages += 1
    
    # åˆ¤æ–­é€»è¾‘
    text_ratio = text_pages / total_checked
    
    if text_ratio >= 0.8:
        pdf_type = 'text'
        print(f"ğŸ“„ æ£€æµ‹ç»“æœ: æ–‡æœ¬å‹PDF (æ–‡æœ¬é¡µ: {text_pages}/{total_checked})")
    elif text_ratio <= 0.2:
        pdf_type = 'image'
        print(f"ğŸ–¼ï¸  æ£€æµ‹ç»“æœ: å›¾ç‰‡å‹PDF (å›¾ç‰‡é¡µ: {image_pages}/{total_checked})")
    else:
        pdf_type = 'mixed'
        print(f"ğŸ“„ğŸ–¼ï¸  æ£€æµ‹ç»“æœ: æ··åˆå‹PDF (æ–‡æœ¬é¡µ: {text_pages}, å›¾ç‰‡é¡µ: {image_pages})")
    
    return pdf_type

def detect_content_area(page, margin_ratio=0.05):
    """
    åŠ¨æ€æ£€æµ‹é¡µé¢å†…å®¹åŒºåŸŸï¼Œè‡ªé€‚åº”è£å‰ª
    
    Args:
        page: pdfplumberé¡µé¢å¯¹è±¡
        margin_ratio: è¾¹è·æ¯”ä¾‹ï¼ˆé»˜è®¤5%ï¼‰
    
    Returns:
        tuple: (x0, y0, x1, y1) å†…å®¹åŒºåŸŸåæ ‡
    """
    width, height = page.width, page.height
    
    # é»˜è®¤è¾¹è·
    default_margin_x = width * margin_ratio
    default_margin_y = height * margin_ratio
    
    # å°è¯•æ£€æµ‹æ–‡æœ¬åˆ†å¸ƒæ¥ç¡®å®šå†…å®¹åŒºåŸŸ
    try:
        # è·å–é¡µé¢ä¸Šæ‰€æœ‰æ–‡æœ¬å¯¹è±¡
        chars = page.chars
        if chars:
            # è®¡ç®—æ–‡æœ¬çš„è¾¹ç•Œ
            x_coords = [char['x0'] for char in chars] + [char['x1'] for char in chars]
            y_coords = [char['top'] for char in chars] + [char['bottom'] for char in chars]
            
            if x_coords and y_coords:
                text_left = min(x_coords)
                text_right = max(x_coords)
                text_top = min(y_coords)
                text_bottom = max(y_coords)
                
                # åœ¨æ–‡æœ¬è¾¹ç•ŒåŸºç¡€ä¸Šé€‚å½“æ‰©å±•
                expand_x = width * 0.02  # 2%æ‰©å±•
                expand_y = height * 0.02
                
                content_x0 = max(0, text_left - expand_x)
                content_y0 = max(0, text_top - expand_y)
                content_x1 = min(width, text_right + expand_x)
                content_y1 = min(height, text_bottom + expand_y)
                
                return (content_x0, content_y0, content_x1, content_y1)
    except:
        pass
    
    # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¾¹è·
    return (
        default_margin_x,
        default_margin_y,
        width - default_margin_x,
        height - default_margin_y
    )

def fix_chinese_soft_breaks(s):
    """ä¿®å¤ä¸­æ–‡æ¢è¡Œå¯¼è‡´çš„æ‹†è¯é—®é¢˜"""
    s = re.sub(r'-\s+', '', s)
    s = re.sub(r'(?<=[\u4e00-\u9fa5])\s+(?=[\u4e00-\u9fa5])', '', s)
    return s

def preprocess_image(img):
    """å›¾ç‰‡é¢„å¤„ç†ï¼Œæé«˜OCRè¯†åˆ«ç‡"""
    # è½¬æ¢ä¸ºç°åº¦å›¾
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img
    
    # å›¾ç‰‡å¢å¼º
    # 1. é«˜æ–¯å»å™ª
    denoised = cv2.GaussianBlur(gray, (3, 3), 0)
    
    # 2. å¯¹æ¯”åº¦å¢å¼º
    pil_img = Image.fromarray(denoised)
    enhancer = ImageEnhance.Contrast(pil_img)
    enhanced = enhancer.enhance(1.5)  # å¢å¼ºå¯¹æ¯”åº¦
    
    # 3. é”åŒ–
    sharpness_enhancer = ImageEnhance.Sharpness(enhanced)
    sharpened = sharpness_enhancer.enhance(1.2)
    
    # è½¬æ¢å›opencvæ ¼å¼
    processed_img = np.array(sharpened)
    
    return processed_img

def process_text_with_paragraphs(text_lines, debug=False):
    """ä¿®æ”¹ç‰ˆï¼šä»…å¤„ç†å¸¦æ‹¬å·çš„ç¼–å·"""
    text_output = []
    current_para = []
    merged_lines = []

    # ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½åˆå¹¶è¢«æ‹†åˆ†çš„æ®µè½è¡Œï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    buffer = ""
    for line in (l.strip() for l in text_lines if l.strip()):
        # ä»…æ£€æµ‹å¸¦æ‹¬å·çš„ç¼–å·ä½œä¸ºæ–°æ®µè½èµ·å§‹
        if re.match(r'^[\[\(\ã€ï¼ˆï¼»]+.*\d+.*[\]ï¼‰\ã€‘ï¼½]*', line):  # ä¿®æ”¹è¡Œåˆå¹¶æ¡ä»¶
            if buffer:
                merged_lines.append(buffer)
                buffer = ""
        buffer = f"{buffer} {line}".strip() if buffer else line
    
    if buffer:
        merged_lines.append(buffer)

    # ç¬¬äºŒé˜¶æ®µï¼šç²¾ç¡®åŒ¹é…å¸¦æ‹¬å·çš„ç¼–å·
    para_pattern = re.compile(
        r'^('
        r'[\[\(\ã€ï¼ˆ\ï¼»]+\d+[\]ï¼‰\ã€‘ï¼½]*'  # æœ‰å‰æ‹¬å·
        r'|'                             # æˆ– 
        r'\d+[\]ï¼‰\ã€‘\ï¼½]+'               # æœ‰åæ‹¬å·
        r')'
        r'[\.\ã€‚]?'          # å¯é€‰ç»“æŸç¬¦
        r'\s*'               # åç»­ç©ºæ ¼
    )

    for line in merged_lines:
        if debug:
            print(f"å¤„ç†åˆå¹¶è¡Œ: {line[:60]}...")

        # ä»…åŒ¹é…å¸¦æ‹¬å·çš„ç¼–å·
        match = para_pattern.match(line)
        if match:
            # è®¡ç®—ç¼–å·éƒ¨åˆ†é•¿åº¦ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            match_len = match.end()
            remaining = line[match_len:].strip()

            # ä¿å­˜ä¸Šä¸€ä¸ªæ®µè½ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if current_para:
                joined = fix_chinese_soft_breaks(" ".join(current_para))
                text_output.append(joined)
                current_para = []
            
            if remaining:
                current_para.append(remaining)
        else:
            # æ— ç¼–å·å†…å®¹å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if current_para:
                current_para.append(line)
            else:
                cleaned = fix_chinese_soft_breaks(line)
                text_output.append(cleaned)

    # å¤„ç†æœ€åä¸€æ®µï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    if current_para:
        joined = fix_chinese_soft_breaks(" ".join(current_para))
        text_output.append(joined)

    return text_output

def extract_images_tables_with_ppstructure(pdf_path, page_num, current_id, img_counter, table_counter, img_dir, para_buffer):
    """ä½¿ç”¨PPStructureæå–å•é¡µçš„å›¾ç‰‡å’Œè¡¨æ ¼"""
    
    structure_engine = PPStructure(
        recovery=False,
        lang='ch',
        show_log=False
    )
    
    pdf_document = fitz.open(pdf_path)
    page = pdf_document[page_num]
    
    mat = fitz.Matrix(2.0, 2.0)
    pix = page.get_pixmap(matrix=mat)
    img_data = pix.tobytes("png")
    
    nparr = np.frombuffer(img_data, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    try:
        result = structure_engine(img)
        result.sort(key=lambda x: x['bbox'][1])
        
        for item in result:
            bbox = item['bbox']
            item_type = item['type']
            
            if item_type == 'figure':
                img_counter += 1
                x0, y0, x1, y1 = [int(coord) for coord in bbox]
                cropped_img = img[y0:y1, x0:x1]
                img_name = f"{current_id}_{img_counter}.png" if current_id else f"page{page_num+1}_img{img_counter}.png"
                img_path = os.path.join(img_dir, img_name)
                cv2.imwrite(img_path, cropped_img)
                para_buffer += f"\n[IMG_{img_counter}]"
                print(f"ğŸ“· æå–å›¾ç‰‡: {img_name}")
            
            elif item_type == 'table':
                table_counter += 1
                x0, y0, x1, y1 = [int(coord) for coord in bbox]
                cropped_table = img[y0:y1, x0:x1]
                table_name = f"{current_id}_table{table_counter}.png" if current_id else f"page{page_num+1}_table{table_counter}.png"
                table_path = os.path.join(img_dir, table_name)
                cv2.imwrite(table_path, cropped_table)
                para_buffer += f"\n[TABLE_{table_counter}]"
                print(f"ğŸ“Š æå–è¡¨æ ¼: {table_name}")
    
    except Exception as e:
        print(f"âš ï¸ PPStructureå¤„ç†ç¬¬{page_num+1}é¡µæ—¶å‡ºé”™: {str(e)}")
    
    finally:
        pdf_document.close()
    
    return img_counter, table_counter, para_buffer

def extract_text_pdf_fixed(pdf_path, output_dir):
    """
    ä¿®å¤ç‰ˆæ–‡æœ¬å‹PDFå¤„ç†å™¨ - è§£å†³æ–‡æœ¬ä¸¢å¤±é—®é¢˜
    
    ä¸»è¦ä¿®å¤ï¼š
    1. ä¸ä¾èµ–ç‰¹å®šç¼–å·æ ¼å¼ï¼Œä¿å­˜æ‰€æœ‰æ–‡æœ¬
    2. åŠ¨æ€æ£€æµ‹å†…å®¹åŒºåŸŸ
    3. æ”¹è¿›æ®µè½åˆ†å‰²é€»è¾‘
    """
    print("ğŸ“„ ä½¿ç”¨ä¿®å¤ç‰ˆæ–‡æœ¬å‹PDFå¤„ç†æ¨¡å¼...")
    
    os.makedirs(output_dir, exist_ok=True)
    img_dir = os.path.join(output_dir, "images")
    os.makedirs(img_dir, exist_ok=True)
    
    text_output = []
    img_counter = 0
    table_counter = 0
    all_text_lines = []  # æ”¶é›†æ‰€æœ‰æ–‡æœ¬è¡Œ
    
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            print(f"å¤„ç†ç¬¬ {page_num + 1}/{len(pdf.pages)} é¡µ")
            
            # åŠ¨æ€æ£€æµ‹å†…å®¹åŒºåŸŸ
            content_area = detect_content_area(page)
            crop = page.within_bbox(content_area)
            text = crop.extract_text()
            
            if not text:
                print(f"  âš ï¸ ç¬¬{page_num+1}é¡µæœªæå–åˆ°æ–‡æœ¬")
                continue
            
            # æŒ‰è¡Œåˆ†å‰²å¹¶æ¸…ç†
            lines = [line.strip() for line in text.split('\n') if line.strip()]
            all_text_lines.extend(lines)
            with open(os.path.join(output_dir, "raw_lines.txt"), "w", encoding="utf-8") as f:
                for i, line in enumerate(all_text_lines):
                    f.write(f"{i+1:04d}: {repr(line)}\n")

            
            print(f"  ğŸ“ æå–äº† {len(lines)} è¡Œæ–‡æœ¬")
            
            # PPStructureå¢å¼ºå›¾ç‰‡è¡¨æ ¼æå–
            try:
                # ä¸ºäº†å…¼å®¹åŸæœ‰é€»è¾‘ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ªä¸´æ—¶çš„para_buffer
                temp_para_buffer = ""
                img_counter, table_counter, _ = extract_images_tables_with_ppstructure(
                    pdf_path, page_num, None, img_counter, table_counter, img_dir, temp_para_buffer
                )
            except Exception as e:
                print(f"âš ï¸ é¡µé¢{page_num+1}çš„PPStructureå¤„ç†å¤±è´¥: {str(e)}")
    
    # æ™ºèƒ½å¤„ç†æ–‡æœ¬æ®µè½
    print(f"ğŸ”„ å¤„ç†æå–çš„æ–‡æœ¬ï¼Œå…± {len(all_text_lines)} è¡Œ")
    
    # æ”¹è¿›çš„æ®µè½åˆ†å‰²é€»è¾‘
    text_output = smart_paragraph_split(all_text_lines)
    
    # ä¿å­˜æ–‡æœ¬
    text_file = os.path.join(output_dir, "text.txt")
    with open(text_file, "w", encoding="utf-8") as f:
        f.write("\n\n".join(text_output))  # æ®µè½é—´ç”¨åŒæ¢è¡Œåˆ†éš”
    
    print(f"âœ… æ–‡æœ¬æå–å®Œæˆï¼Œå…± {len(text_output)} ä¸ªæ®µè½")
    
    return len(text_output), img_counter, table_counter

import re

def smart_paragraph_split(text_lines):
    paragraphs = []
    current_paragraph = []

    # å¸¸è§ç¼–å·æ ¼å¼
    number_patterns = [
        r'^\d+[\.\ï¼]',                    # 1. 2. 3.
        r'^[\[\(ï¼ˆ\ï¼ˆ]+\d+[\]\)ï¼‰\ï¼‰]+',    # [1] (1) ï¼ˆ1ï¼‰
        r'^\d+[\)ï¼‰]',                    # 1) 2)
    ]

    # ç»“æ„æ€§æ ‡é¢˜å…³é”®è¯
    SECTION_TITLES = {
        "æŠ€æœ¯é¢†åŸŸ": ["æŠ€æœ¯é¢†åŸŸ"],
        "èƒŒæ™¯æŠ€æœ¯": ["èƒŒæ™¯æŠ€æœ¯"],
        "å‘æ˜å†…å®¹": ["å‘æ˜å†…å®¹", "å®ç”¨æ–°å‹å†…å®¹"],
        "é™„å›¾è¯´æ˜": ["é™„å›¾è¯´æ˜"],
        "å…·ä½“å®æ–½æ–¹å¼": ["å…·ä½“å®æ–½æ–¹å¼"]
    }

    def is_numbered_line(line):
        for pattern in number_patterns:
            if re.match(pattern, line):
                return True
        return False

    def is_title_like(line):
        return len(line) < 50 and (line.isupper() or line.endswith('ï¼š') or line.endswith(':'))

    def is_section_title(line):
        stripped = line.strip().replace(" ", "")
        for section, aliases in SECTION_TITLES.items():
            for alias in aliases:
                if stripped == alias:
                    return section
        return None

    def fix_chinese_soft_breaks(s):
        s = re.sub(r'-\s+', '', s)
        s = re.sub(r'(?<=[\u4e00-\u9fa5])\s+(?=[\u4e00-\u9fa5])', '', s)
        return s

    for i, line in enumerate(text_lines):
        line = line.strip()
        if not line:
            continue

        section = is_section_title(line)
        if section:
            # ä¿å­˜å½“å‰æ®µè½
            if current_paragraph:
                paragraph_text = fix_chinese_soft_breaks(" ".join(current_paragraph))
                if paragraph_text.strip():
                    paragraphs.append(paragraph_text)
                current_paragraph = []

            # å°æ ‡é¢˜ç‹¬ç«‹æˆæ®µ
            paragraphs.append(section)
            continue

        is_new_paragraph = False
        if is_numbered_line(line):
            is_new_paragraph = True
        elif is_title_like(line):
            is_new_paragraph = True
        elif i > 0 and len(line) < 20 and not line.endswith(('ï¼Œ', 'ã€‚', 'ï¼›', 'ï¼š', ',', '.', ';', ':')):
            is_new_paragraph = True

        if is_new_paragraph and current_paragraph:
            paragraph_text = fix_chinese_soft_breaks(" ".join(current_paragraph))
            if paragraph_text.strip():
                paragraphs.append(paragraph_text)
            current_paragraph = []

        current_paragraph.append(line)

    if current_paragraph:
        paragraph_text = fix_chinese_soft_breaks(" ".join(current_paragraph))
        if paragraph_text.strip():
            paragraphs.append(paragraph_text)

    # è¿‡æ»¤è¿‡çŸ­çš„æ®µè½ï¼ˆå¯èƒ½æ˜¯å™ªå£°ï¼‰
    filtered_paragraphs = [p for p in paragraphs if len(p.strip()) > 1]

    return filtered_paragraphs

def extract_image_pdf(pdf_path, output_dir, debug=False):
    """
    å¢å¼ºç‰ˆå›¾ç‰‡å‹PDFå¤„ç†å™¨ - é›†æˆè‡ªscript2
    
    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        debug: æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯å’Œä¸­é—´æ–‡ä»¶
    """
    
    print(f"ğŸ–¼ï¸ ä½¿ç”¨å¢å¼ºç‰ˆå›¾ç‰‡å‹PDFå¤„ç†æ¨¡å¼: {os.path.basename(pdf_path)}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    img_dir = os.path.join(output_dir, "images")
    os.makedirs(img_dir, exist_ok=True)
    
    if debug:
        debug_dir = os.path.join(output_dir, "debug")
        os.makedirs(debug_dir, exist_ok=True)
    
    # åˆå§‹åŒ–OCRå¼•æ“
    print("ğŸ”§ åˆå§‹åŒ–OCRå¼•æ“...")
    ocr_engine = PaddleOCR(
        use_angle_cls=True,
        lang='ch',
        use_gpu=False,
        show_log=False
    )
    
    # åˆå§‹åŒ–ç»“æ„åˆ†æå¼•æ“
    print("ğŸ”§ åˆå§‹åŒ–ç»“æ„åˆ†æå¼•æ“...")
    structure_engine = PPStructure(
        recovery=True,
        lang='ch',
        show_log=False
    )
    
    # æ‰“å¼€PDF
    pdf_document = fitz.open(pdf_path)
    total_pages = pdf_document.page_count
    
    all_text_lines = []  # æ”¶é›†æ‰€æœ‰æ–‡æœ¬è¡Œ
    img_counter = 0
    table_counter = 0
    
    print(f"ğŸ“– PDFæ€»é¡µæ•°: {total_pages}")
    
    for page_num in range(total_pages):
        print(f"\n--- ğŸ“„ å¤„ç†ç¬¬ {page_num + 1}/{total_pages} é¡µ ---")
        
        page = pdf_document[page_num]
        
        # è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡
        mat = fitz.Matrix(3.0, 3.0)
        pix = page.get_pixmap(matrix=mat)
        img_data = pix.tobytes("png")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        nparr = np.frombuffer(img_data, np.uint8)
        original_img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if debug:
            debug_img_path = os.path.join(debug_dir, f"page_{page_num+1}_original.png")
            cv2.imwrite(debug_img_path, original_img)
            print(f"ğŸ” åŸå§‹å›¾ç‰‡å·²ä¿å­˜: {debug_img_path}")
        
        # å›¾ç‰‡é¢„å¤„ç†
        processed_img = preprocess_image(original_img)
        
        if debug:
            debug_processed_path = os.path.join(debug_dir, f"page_{page_num+1}_processed.png")
            cv2.imwrite(debug_processed_path, processed_img)
            print(f"ğŸ” é¢„å¤„ç†å›¾ç‰‡å·²ä¿å­˜: {debug_processed_path}")
        
        page_text_lines = []
        structure_success = False
        
        # æ–¹æ³•1: å°è¯•ä½¿ç”¨PPStructureè¿›è¡Œç»“æ„åŒ–åˆ†æ
        print("ğŸ”¬ å°è¯•PPStructureç»“æ„åŒ–åˆ†æ...")
        try:
            structure_result = structure_engine(original_img)
            
            if structure_result:
                # æŒ‰yåæ ‡æ’åºï¼Œä¿è¯é˜…è¯»é¡ºåº
                structure_result.sort(key=lambda x: x['bbox'][1])
                
                for item in structure_result:
                    bbox = item['bbox']
                    item_type = item['type']
                    
                    if debug:
                        print(f"  å‘ç°{item_type}: {bbox}")
                    
                    if item_type == 'text':
                        # å¤„ç†æ–‡æœ¬åŒºåŸŸ
                        text_content = item.get('res', [])
                        if isinstance(text_content, list) and text_content:
                            for text_item in text_content:
                                if isinstance(text_item, dict) and 'text' in text_item:
                                    confidence = text_item.get('confidence', 0)
                                    if confidence > 0.5:
                                        page_text_lines.append(text_item['text'])
                                        structure_success = True
                                elif isinstance(text_item, str):
                                    page_text_lines.append(text_item)
                                    structure_success = True
                    
                    elif item_type == 'figure':
                        # å¤„ç†å›¾ç‰‡
                        img_counter += 1
                        x0, y0, x1, y1 = [int(coord) for coord in bbox]
                        
                        h, w = original_img.shape[:2]
                        x0, x1 = max(0, min(x0, w)), max(0, min(x1, w))
                        y0, y1 = max(0, min(y0, h)), max(0, min(y1, h))
                        
                        if x1 > x0 and y1 > y0:
                            cropped_img = original_img[y0:y1, x0:x1]
                            img_name = f"page{page_num+1}_img{img_counter}.png"
                            img_path = os.path.join(img_dir, img_name)
                            cv2.imwrite(img_path, cropped_img)
                            
                            # åœ¨æ–‡æœ¬ä¸­æ’å…¥å›¾ç‰‡æ ‡è®°
                            page_text_lines.append(f"[IMG_{img_counter}]")
                            print(f"  ğŸ“· æå–å›¾ç‰‡: {img_name}")
                    
                    elif item_type == 'table':
                        # å¤„ç†è¡¨æ ¼
                        table_counter += 1
                        x0, y0, x1, y1 = [int(coord) for coord in bbox]
                        
                        h, w = original_img.shape[:2]
                        x0, x1 = max(0, min(x0, w)), max(0, min(x1, w))
                        y0, y1 = max(0, min(y0, h)), max(0, min(y1, h))
                        
                        if x1 > x0 and y1 > y0:
                            cropped_table = original_img[y0:y1, x0:x1]
                            table_name = f"page{page_num+1}_table{table_counter}.png"
                            table_path = os.path.join(img_dir, table_name)
                            cv2.imwrite(table_path, cropped_table)
                            
                            # åœ¨æ–‡æœ¬ä¸­æ’å…¥è¡¨æ ¼æ ‡è®°
                            page_text_lines.append(f"[TABLE_{table_counter}]")
                            print(f"  ğŸ“Š æå–è¡¨æ ¼: {table_name}")
        
        except Exception as e:
            print(f"âš ï¸ PPStructureåˆ†æå¤±è´¥: {str(e)}")
        
        # æ–¹æ³•2: å¦‚æœPPStructureæ²¡æœ‰æˆåŠŸæå–æ–‡æœ¬ï¼Œä½¿ç”¨çº¯OCR
        if not structure_success:
            print("ğŸ”¤ ä½¿ç”¨çº¯OCRæ¨¡å¼...")
            try:
                # ä½¿ç”¨é¢„å¤„ç†åçš„å›¾ç‰‡è¿›è¡ŒOCR
                ocr_result = ocr_engine.ocr(processed_img, cls=True)
                
                if ocr_result and ocr_result[0]:
                    # æŒ‰ç…§yåæ ‡æ’åºOCRç»“æœ
                    ocr_lines = sorted(ocr_result[0], key=lambda x: x[0][0][1])
                    
                    for line in ocr_lines:
                        text = line[1][0]
                        confidence = line[1][1]
                        
                        # ç½®ä¿¡åº¦è¿‡æ»¤
                        if confidence > 0.6:
                            page_text_lines.append(text)
                            if debug:
                                print(f"  OCR: {text} (ç½®ä¿¡åº¦: {confidence:.2f})")
                else:
                    print("  âš ï¸ OCRè¿”å›ç©ºç»“æœ")
            
            except Exception as e:
                print(f"âŒ OCRå¤„ç†å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºé¡µé¢æå–çš„æ–‡æœ¬é¢„è§ˆ
        if page_text_lines:
            page_text_preview = ' '.join(page_text_lines)
            if debug:
                print(f"  ğŸ“ é¡µé¢æ–‡æœ¬é¢„è§ˆ: {page_text_preview[:100]}...")
            # å°†é¡µé¢æ–‡æœ¬æ·»åŠ åˆ°æ€»æ–‡æœ¬ä¸­
            all_text_lines.extend(page_text_lines)
        else:
            print("  âš ï¸ æœ¬é¡µæœªæå–åˆ°æ–‡æœ¬")
    
    pdf_document.close()
    
    # ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ–‡æœ¬ï¼Œåº”ç”¨æ®µè½è¯†åˆ«é€»è¾‘
    print(f"\nğŸ”„ å¤„ç†æå–çš„æ–‡æœ¬ï¼Œå…± {len(all_text_lines)} è¡Œ")
    
    if debug:
        print("ğŸ“ æ‰€æœ‰æå–çš„æ–‡æœ¬è¡Œé¢„è§ˆ:")
        for i, line in enumerate(all_text_lines[:10]):  # åªæ˜¾ç¤ºå‰10è¡Œ
            print(f"  {i+1}: {line}")
        if len(all_text_lines) > 10:
            print(f"  ... è¿˜æœ‰ {len(all_text_lines)-10} è¡Œ")
    
    # ä½¿ç”¨æ”¹è¿›çš„æ®µè½åˆ†å‰²é€»è¾‘
    text_output = smart_paragraph_split(all_text_lines)
    
    # å†™å…¥æ–‡æœ¬æ–‡ä»¶
    text_file = os.path.join(output_dir, "description.txt")
    with open(text_file, "w", encoding="utf-8") as f:
        f.write("\n\n".join(text_output))  # æ®µè½é—´ç”¨åŒæ¢è¡Œåˆ†éš”
    
    # åŒæ—¶ä¿å­˜åŸå§‹æå–çš„æ–‡æœ¬ï¼ˆè°ƒè¯•ç”¨ï¼‰
    if debug:
        debug_dir = os.path.join(output_dir, "debug")
        raw_text_file = os.path.join(debug_dir, "raw_text.txt")
        with open(raw_text_file, "w", encoding="utf-8") as f:
            f.write("\n".join(all_text_lines))
        print(f"ğŸ” åŸå§‹æ–‡æœ¬å·²ä¿å­˜: {raw_text_file}")
    
    return len(text_output), img_counter, table_counter

def smart_extract_pdf(pdf_path, output_dir, debug=False):
    """æ™ºèƒ½PDFæå– - è‡ªåŠ¨åˆ¤æ–­ç±»å‹å¹¶é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹æ³•"""
    
    print(f"ğŸš€ å¼€å§‹æ™ºèƒ½å¤„ç†PDF: {os.path.basename(pdf_path)}")
    
    # ç¬¬ä¸€æ­¥ï¼šæ£€æµ‹PDFç±»å‹
    pdf_type = detect_pdf_type(pdf_path)
    
    # ç¬¬äºŒæ­¥ï¼šé€‰æ‹©å¯¹åº”çš„å¤„ç†æ–¹æ³•
    if pdf_type == 'text':
        paragraphs, images, tables = extract_text_pdf_fixed(pdf_path, output_dir)  # ä½¿ç”¨ä¿®å¤ç‰ˆ
    elif pdf_type == 'image':
        paragraphs, images, tables = extract_image_pdf(pdf_path, output_dir, debug=debug)
    else:  # mixed
        print("ğŸ“„ğŸ–¼ï¸ æ··åˆå‹PDFï¼Œä½¿ç”¨ä¿®å¤ç‰ˆæ–‡æœ¬æ¨¡å¼å¤„ç†ï¼ˆä¸»è¦é€»è¾‘ï¼‰+ OCRè¡¥å……")
        # æ··åˆå‹ä½¿ç”¨ä¿®å¤ç‰ˆæ–‡æœ¬æ¨¡å¼ï¼Œåç»­å¯ä»¥ä¼˜åŒ–ä¸ºé€é¡µåˆ¤æ–­
        paragraphs, images, tables = extract_text_pdf_fixed(pdf_path, output_dir)
    
    print(f"\nâœ… å¤„ç†å®Œæˆï¼")
    print(f"   ğŸ“Š PDFç±»å‹: {pdf_type}")
    print(f"   ğŸ“„ æ®µè½æ•°: {paragraphs}")
    print(f"   ğŸ“· å›¾ç‰‡æ•°: {images}")
    print(f"   ğŸ“‹ è¡¨æ ¼æ•°: {tables}")
    print(f"   ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    return {
        'pdf_type': pdf_type,
        'paragraphs': paragraphs,
        'images': images,
        'tables': tables
    }

# ç”¨æ³•ç¤ºä¾‹
if __name__ == "__main__":
    pdf_path = r"/workspace/project/output/descriptions.pdf"
    output_dir = "output_descriptions"
    
    try:
        # å¼€å¯è°ƒè¯•æ¨¡å¼ä»¥è·å¾—æ›´è¯¦ç»†çš„è¾“å‡ºå’Œä¸­é—´æ–‡ä»¶
        result = smart_extract_pdf(pdf_path, output_dir, debug=True)
        
        print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š")
        print(f"   ğŸ“„ text.txt - ç»“æ„åŒ–æ–‡æœ¬ ({result['paragraphs']} æ®µè½)")
        print(f"   ğŸ“ images/ - {result['images']} ä¸ªå›¾ç‰‡ + {result['tables']} ä¸ªè¡¨æ ¼")
        print(f"   ğŸ” PDFç±»å‹: {result['pdf_type']}")
        
        # å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼ï¼Œè¿˜ä¼šç”Ÿæˆdebugæ–‡ä»¶å¤¹
        debug_dir = os.path.join(output_dir, "debug")
        if os.path.exists(debug_dir):
            print(f"   ğŸ” debug/ - è°ƒè¯•æ–‡ä»¶ï¼ˆåŸå§‹å›¾ç‰‡ã€å¤„ç†åå›¾ç‰‡ã€åŸå§‹æ–‡æœ¬ç­‰ï¼‰")
        
    except ImportError as e:
        print(f"âŒ ä¾èµ–åº“ç¼ºå¤±: {str(e)}")
        print("ğŸ’¡ è¯·å®‰è£…: pip install paddlepaddle paddleocr PyMuPDF opencv-python pdfplumber pillow")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()